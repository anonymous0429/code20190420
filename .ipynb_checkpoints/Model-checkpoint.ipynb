{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import ProcessData\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import torch\n",
    "from conv import GraphConv\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from dgl import DGLGraph\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#留给GPU的接口\n",
    "def create_variable(tensor):\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>RNN 部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,hidden_size,output_size,n_layers=1,bidirectional=True):\n",
    "        super(RNNEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_directions = int(bidirectional) + 1\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,bidirectional=bidirectional)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, seq_lengths):\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        # input shape: B x S (input size)\n",
    "        # transpose to make S(sequence) x B (batch)\n",
    "        input = input.t()\n",
    "        batch_size = input.size(1)\n",
    "\n",
    "        # Make a hidden\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "\n",
    "        # Embedding S x B -> S x B x I (embedding size)\n",
    "        #print(\"s*b\",input.size())\n",
    "        embedded = self.embedding(input.long())\n",
    "        #print(\"s*b*i\",embedded.size())\n",
    "        # Pack them up nicely\n",
    "        #gru_input = pack_padded_sequence(embedded, seq_lengths.data.cpu().numpy())\n",
    "\n",
    "        # To compact weights again call flatten_parameters().\n",
    "        self.gru.flatten_parameters()\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "\n",
    "        # Use the last layer output as FC's input\n",
    "        # No need to unpack, since we are going to use hidden\n",
    "        fc_output = self.fc(hidden[-1])\n",
    "        return fc_output\n",
    "    def _init_hidden(self,batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.n_directions,\n",
    "                            batch_size,self.hidden_size)\n",
    "        return create_variable(hidden)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>GCN：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#消息传递函数\n",
    "gcn_msg = fn.copy_src(src='h', out='m')\n",
    "gcn_reduce = fn.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeApplyModule(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        h = self.activation(h)\n",
    "        return {'h' : h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        g.ndata['h'] = feature\n",
    "        g.update_all(gcn_msg, gcn_reduce)\n",
    "        #print(g.ndata)\n",
    "        g.apply_nodes(func=self.apply_mod)#dgl.DGLGraph.apply_nodes\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, g, in_feats, n_hidden, n_classes, n_layers, activation, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.g = g\n",
    "        self.layers = nn.ModuleList()\n",
    "        # input layer\n",
    "        self.layers.append(GraphConv(in_feats, n_hidden, activation=activation))\n",
    "        # hidden layers\n",
    "        for i in range(n_layers - 1):\n",
    "            self.layers.append(GraphConv(n_hidden, n_hidden, activation=activation))\n",
    "        # output layer\n",
    "        self.layers.append(GraphConv(n_hidden, n_classes))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, features):\n",
    "        h = features\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i != 0:\n",
    "                h = self.dropout(h)\n",
    "            h = layer(h, self.g)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class GCN_Plus_RNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 RNN_input_size,\n",
    "                 RNN_hidden_size,\n",
    "                 GCN_input_size,\n",
    "                 GCN_hidden_size,\n",
    "                 Num_classes,\n",
    "                 Num_layers,\n",
    "                 dropout,\n",
    "                 activation):\n",
    "        super(GCN_Plus_RNN, self).__init__()\n",
    "        \n",
    "        self.RNN = RNNEncoder(RNN_input_size,RNN_hidden_size,GCN_input_size)\n",
    "        self.gcn = GCN(g,GCN_input_size,GCN_hidden_size,Num_classes,Num_layers,activation,dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, g, inputs, sequence_length):\n",
    "        features = self.RNN(inputs,sequence_length)      #RNN编码\n",
    "        \n",
    "        x = self.gcn(features)             #第一层gcn对feature卷积\n",
    "        #x = self.gcn1(g, features) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> GCN+RNN\n",
    "#### <b> 去掉了一层GCN效果更好些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_and_RNN(nn.Module):\n",
    "    def __init__(self, RNN_input_size,RNN_hidden_size,GCN_input_size,GCN_hidden_size,GCN_output_size,Num_classes,activation):\n",
    "        super(GCN_and_RNN, self).__init__()\n",
    "        \n",
    "        self.RNN = RNNEncoder(RNN_input_size,RNN_hidden_size,GCN_input_size)\n",
    "        self.gcn1 = GCN(GCN_input_size,GCN_hidden_size,activation)\n",
    "        self.gcn2 = GCN(GCN_hidden_size,GCN_output_size,activation)\n",
    "        \n",
    "        #逻辑回归\n",
    "        self.linear = nn.Linear(GCN_hidden_size, Num_classes)\n",
    "\n",
    "        #self.linear = nn.Linear(GCN_output_size, Num_classes)\n",
    "    def forward(self, g, inputs, sequence_length):\n",
    "        features = self.RNN(inputs,sequence_length)      #RNN编码\n",
    "        \n",
    "        x = self.gcn1(g, features)             #第一层gcn对feature卷积\n",
    "        x = self.gcn1(g, features) \n",
    "        #x = self.gcn2(g, x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title,labels,jconf,authors,FullName = ProcessData.ProcessingRawData(\"LeiWang.xml\")\n",
    "title = ProcessData.Wipe_off_Punctuation(title)\n",
    "title_vocab,title_split = ProcessData.Split_Title(title)\n",
    "title_one_hot,Max_Sequence_Len,vocab_size = ProcessData.One_hot_encoding(title_vocab,title_split)\n",
    "title_one_hot_padding = ProcessData.Padding_One_hot(title_one_hot,Max_Sequence_Len)\n",
    "author_vocab,authors_split = ProcessData.Split_Authors(authors)\n",
    "len(authors_split)\n",
    "len(title_one_hot_padding)\n",
    "# vocab_size\n",
    "max(labels)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> 构造关系图:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Graph(g,full_name,authors_split):\n",
    "    g.add_nodes(len(authors_split))\n",
    "    for i in range(len(authors_split)):\n",
    "        for j in range(len(authors_split)):\n",
    "            if jconf[i] == jconf[j]:\n",
    "                g.add_edges(i,j)\n",
    "            for k in range(len(authors_split[i])):\n",
    "                if  authors_split[i][k] in authors_split[j] and authors_split[i][k] != full_name:\n",
    "                    #print(\"name: \",authors_split[i][k],\"i: \",i,\"j: \",j)\n",
    "                    g.add_edges(i,j)\n",
    "                    break;\n",
    "    #return g\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.DGLGraph()\n",
    "Create_Graph(g,FullName,authors_split)\n",
    "# nx.draw(g.to_networkx(), with_labels=True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges:  2743\n",
      "Number of nodes:  308\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of edges: \",len(g.edges()[0]))\n",
    "print(\"Number of nodes: \",len(authors_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = labels\n",
    "inputs = create_variable(torch.Tensor(title_one_hot_padding))\n",
    "labels_y = create_variable(torch.LongTensor(y_data))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RNN_input_size = vocab_size\n",
    "RNN_hidden_size = 100\n",
    "GCN_input_size = 75\n",
    "GCN_hidden_size = 20\n",
    "Num_classes = max(labels)+1\n",
    "Num_layers = 1\n",
    "dropout = 0.5\n",
    "activation = F.relu\n",
    "sequence_length = inputs.size()[1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model=GCN_Plus_RNN(g,RNN_input_size,RNN_hidden_size,GCN_input_size,GCN_hidden_size,Num_classes,Num_layers,dropout,activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前的RNN_and_GCN输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_input_size = vocab_size #one-hot length/ number of words\n",
    "RNN_hidden_size = 100\n",
    "GCN_input_size = 75\n",
    "GCN_hidden_size = 20\n",
    "GCN_output_size = 40\n",
    "Num_classes = max(labels)+1\n",
    "sequence_length = inputs.size()[1]\n",
    "activation = F.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1153"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机抽样样本"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training_idx = random.sample(range(len(authors_split)),270)\n",
    "test_idx = []\n",
    "for i in range(len(authors_split)):\n",
    "     if i not in training_idx:\n",
    "        test_idx.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用新的抽样方法，每个节点一个"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training_idx = []\n",
    "test_idx = []\n",
    "for i in range(max(labels)+1):\n",
    "    training_idx.append(labels.index(i))\n",
    "\n",
    "for i in range(len(authors_split)):\n",
    "     if i not in training_idx:\n",
    "        test_idx.append(i)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GCN_and_RNN(RNN_input_size,RNN_hidden_size,GCN_input_size,GCN_hidden_size,GCN_output_size,Num_classes,activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model(g, inputs, sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>定义训练集和测试集index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comput_Accuracy(index):\n",
    "    test_result = output[index]\n",
    "    pred = test_result.data.max(1, keepdim=True)[1]\n",
    "    test_target = labels_y[index]\n",
    "    correct = 0\n",
    "    correct += pred.eq(test_target.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    return float(correct)/len(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7185)\n",
      "Training Accuracy:  0.014814814814814815\n",
      "Test Accuracy:  0.02631578947368421\n",
      "tensor(0.6064)\n",
      "Training Accuracy:  0.825925925925926\n",
      "Test Accuracy:  0.6578947368421053\n",
      "tensor(0.5408)\n",
      "Training Accuracy:  0.8222222222222222\n",
      "Test Accuracy:  0.6578947368421053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-241-0228c373ee29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for i in range(301):\n",
    "    optimizer.zero_grad()\n",
    "    #output = model(g, inputs, sequence_length)\n",
    "    output = model(inputs, sequence_length)\n",
    "    loss = criterion(output[training_idx], labels_y[training_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 50 == 0:\n",
    "        print(loss.data)\n",
    "        print(\"Training Accuracy: \",Comput_Accuracy(training_idx))\n",
    "        print(\"Test Accuracy: \",Comput_Accuracy(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(g, inputs, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333334"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
