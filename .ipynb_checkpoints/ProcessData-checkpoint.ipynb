{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.sax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthorHandler(xml.sax.ContentHandler):\n",
    "    def __init__(self):\n",
    "        self.CurrentData = \"\"\n",
    "        self.personID = \"\"\n",
    "        self.FullName = \"\"\n",
    "        self.FirstName = \"\"\n",
    "        self.LastName = \"\"\n",
    "        self.title = \"\"\n",
    "        self.year = \"\"\n",
    "        self.authors = \"\"\n",
    "        self.jconf = \"\"\n",
    "        self.id = \"\"\n",
    "        self.label = \"\"\n",
    "        self.organization = \"\"\n",
    "    #元素开始事件处理\n",
    "    def startElement(self, tag, attributes):\n",
    "        self.CurrentData = tag\n",
    "       \n",
    "    def endElement(self, tag):\n",
    "        return\n",
    "\n",
    "    def characters(self, content):\n",
    "\n",
    "        if self.CurrentData == \"personID\":\n",
    "            self.personID+=content\n",
    "        elif self.CurrentData == \"FullName\":\n",
    "            self.FullName+=content\n",
    "        elif self.CurrentData == \"FirstName\":\n",
    "            self.FirstName+=content\n",
    "        elif self.CurrentData == \"LastName\":\n",
    "            self.LastName+=content\n",
    "        elif self.CurrentData == \"title\":\n",
    "            self.title+=content\n",
    "        elif self.CurrentData == \"year\":\n",
    "            self.year+=content\n",
    "        elif self.CurrentData == \"authors\":\n",
    "            self.authors+=content\n",
    "        elif self.CurrentData == \"jconf\":\n",
    "            self.jconf+=content\n",
    "        elif self.CurrentData == \"label\":\n",
    "            self.label+=content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wipe_off_Punctuation(str_list):\n",
    "    str_Wiped = []\n",
    "    #去掉title中的标点符号,并且全部转化为小写\n",
    "    Punctuation = [',', ':', '(', ')', '-', '_', ';', '.', '\\'']\n",
    "    for i in range(len(str_list)):\n",
    "        temp = str_list[i]\n",
    "        for j in range(len(Punctuation)):\n",
    "            temp = temp.replace(Punctuation[j],\" \").lower()\n",
    "        str_Wiped.append(temp)\n",
    "    return str_Wiped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split_Title(data):\n",
    "    data_split=copy.deepcopy(data)\n",
    "    Vocab_table=\"\"\n",
    "    \n",
    "    for i in range(len(data_split)):\n",
    "        Vocab_table += (data_split[i])\n",
    "        Vocab_table += \" \"\n",
    "        data_split[i]=data_split[i].split()\n",
    "\n",
    "    Vocab_table = Vocab_table.split()\n",
    "    return Vocab_table,data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split_Authors(data):\n",
    "    #data_split,拆分后的data\n",
    "    data_split = copy.deepcopy(data)\n",
    "    #table是词表\n",
    "    Vocab_table = \"\"\n",
    "    \n",
    "    for i in range(len(data_split)):\n",
    "        Vocab_table += (data_split[i])\n",
    "        Vocab_table += \",\"\n",
    "        data_split[i]=data_split[i].split(\",\")\n",
    "\n",
    "    Vocab_table = Vocab_table.split(',')\n",
    "    return Vocab_table[:-1],data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_hot_encoding(vocabulary,sequence): #生成对应one-hot\n",
    "    vocabulary_one_hot = np.array(vocabulary)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(vocabulary_one_hot)\n",
    "    sequence_encoded = []\n",
    "    Max_Sequence_Len = 0\n",
    "    vocab_size = max(integer_encoded) + 1\n",
    "    #构建one-hot词表    \n",
    "    for i in range(len(sequence)):\n",
    "        if Max_Sequence_Len < len(sequence[i]):\n",
    "            Max_Sequence_Len = len(sequence[i])\n",
    "        sequence_encoded.append(label_encoder.transform(sequence[i]) + 1)\n",
    "    return sequence_encoded,Max_Sequence_Len,vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Padding_One_hot(sequence_encoded,Max_Sequence_Len):\n",
    "    One_hot_Padding = []\n",
    "    for i in range(len(sequence_encoded)):\n",
    "        Padding_ith_sequence = [0 for i in range(Max_Sequence_Len)] \n",
    "        Padding_ith_sequence[0:len(sequence_encoded[i])] = sequence_encoded[i]\n",
    "        One_hot_Padding.append(Padding_ith_sequence)\n",
    "    return One_hot_Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessingRawData(FileName):\n",
    "    # 创建一个 XMLReader\n",
    "    parser = xml.sax.make_parser()\n",
    "    # turn off namepsaces\n",
    "    parser.setFeature(xml.sax.handler.feature_namespaces, 0)\n",
    "\n",
    "    # 重写 ContextHandler\n",
    "    Handler = AuthorHandler()\n",
    "    parser.setContentHandler( Handler )\n",
    "    #parser.parse(\"AjayGupta1.xml\")\n",
    "    parser.parse(FileName)\n",
    "    labels = Handler.label.split(\"\\n\\t\\t\")\n",
    "    labels = list(map(int,labels[:-1]))\n",
    "    jconf = Handler.jconf.split(\"\\n\\t\\t\")\n",
    "    jconf = jconf[:-1]\n",
    "    title = Handler.title.split(\"\\n\\t\\t\")\n",
    "    title = title[:-1]\n",
    "    authors = Handler.authors.split(\"\\n\\t\\t\")\n",
    "    authors = authors[:-1]\n",
    "    FullName = Handler.FullName.split(\"\\n\\t\")\n",
    "    FullName = FullName[0]\n",
    "    return title,labels,jconf,authors,FullName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>读取原始数据："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "title,labels,jconf,authors,FullName = ProcessingRawData(\"AjayGupta1.xml\")\n",
    "#title_list,vocabulary_one_hot,Max_sequence_len = One_hot_encoding(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>对title进行清洗、拆分"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "title = Wipe_off_Punctuation(title)\n",
    "title_vocab,title_split = Split_Title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>对title进行one-hot编码"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "title_one_hot,_ = One_hot_encoding(title_vocab,title_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>对authors进行拆分"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "author_vocab,authors_split = Split_Authors(authors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
